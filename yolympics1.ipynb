{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o modelo\n",
    "# Load the model\n",
    "model = YOLO(\"yolov8n-pose.pt\")  # Carregar um modelo oficial / Load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # Carregar um modelo personalizado / Load a custom model\n",
    "\n",
    "# Definir o diretório de saída\n",
    "# Define the output directory\n",
    "output_dir = 'yolov8/granite-detection/runs'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Definir o caminho do vídeo de entrada e saída\n",
    "# Define the input and output video paths\n",
    "input_video_path = os.path.join(output_dir, 'input_video.mp4')\n",
    "output_video_path = os.path.join(output_dir, 'output_video.mp4')\n",
    "\n",
    "# Abrir o vídeo de entrada\n",
    "# Open the input video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Verificar se o vídeo foi aberto corretamente\n",
    "# Check if the video was opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(f\"Erro ao abrir o vídeo: {input_video_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Obter informações do vídeo\n",
    "# Get video information\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Definir a fração do vídeo a ser processada (10% iniciais)\n",
    "# Define the fraction of the video to be processed (initial 10%)\n",
    "fraction_to_process = 0.1\n",
    "frames_to_process = int(total_frames * fraction_to_process)\n",
    "\n",
    "# Definir o codec e criar o objeto de escrita de vídeo\n",
    "# Define the codec and create the video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Você pode usar 'XVID', 'MJPG', etc. / You can use 'XVID', 'MJPG', etc.\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# IDs dos keypoints para o ombro direito, quadril direito e pés\n",
    "# Keypoint IDs for the right shoulder, right hip, and feet\n",
    "right_shoulder_id = 6  # Ajuste conforme necessário / Adjust as needed\n",
    "right_hip_id = 12  # Ajuste conforme necessário / Adjust as needed\n",
    "right_foot_id = 16  # Ajuste conforme necessário / Adjust as needed\n",
    "left_foot_id = 15  # Ajuste conforme necessário / Adjust as needed\n",
    "\n",
    "# Listas para armazenar as posições do ombro direito, quadril direito e pés\n",
    "# Lists to store the positions of the right shoulder, right hip, and feet\n",
    "right_shoulder_positions = []\n",
    "right_hip_positions = []\n",
    "right_foot_positions = []\n",
    "left_foot_positions = []\n",
    "\n",
    "# Definir confiança mínima\n",
    "# Define minimum confidence\n",
    "min_confidence = 0.5\n",
    "\n",
    "# Definir um limite mínimo de movimento (em pixels)\n",
    "# Define a minimum movement threshold (in pixels)\n",
    "min_movement_threshold = 5\n",
    "\n",
    "# Função para contar giros\n",
    "# Function to count spins\n",
    "def count_spins(positions):\n",
    "    spins = 0\n",
    "    for i in range(1, len(positions) - 1):\n",
    "        if abs(positions[i-1][0] - positions[i][0]) > min_movement_threshold and \\\n",
    "           abs(positions[i+1][0] - positions[i][0]) > min_movement_threshold:\n",
    "            spins += 1\n",
    "    return spins\n",
    "\n",
    "# Função para classificar movimentos\n",
    "# Function to classify movements\n",
    "def classify_movement(spins):\n",
    "    if spins == 1:\n",
    "        return \"Movimento A\"\n",
    "    elif spins == 1.5:\n",
    "        return \"Movimento B\"\n",
    "    elif spins == 2:\n",
    "        return \"Movimento C\"\n",
    "    else:\n",
    "        return \"Movimento Desconhecido\"\n",
    "\n",
    "# Função para calcular a velocidade dos pés\n",
    "# Function to calculate foot speed\n",
    "def calculate_speed(foot_positions, fps):\n",
    "    speeds = []\n",
    "    for i in range(1, len(foot_positions)):\n",
    "        distance = np.linalg.norm(np.array(foot_positions[i]) - np.array(foot_positions[i-1]))\n",
    "        speed = distance * fps\n",
    "        speeds.append(speed)\n",
    "    return speeds\n",
    "\n",
    "# Função para determinar se a pessoa está correndo ou andando\n",
    "# Function to determine if the person is running or walking\n",
    "def detect_running_walking(speeds, threshold=5.0):\n",
    "    running = sum(speed > threshold for speed in speeds)\n",
    "    walking = len(speeds) - running\n",
    "    return running, walking\n",
    "\n",
    "# Variáveis para contagem de saltos, giros e passos\n",
    "# Variables for counting jumps, spins, and steps\n",
    "in_air = False\n",
    "jumps = 0\n",
    "spins_per_jump = []\n",
    "total_air_spins = 0\n",
    "total_ground_spins = 0\n",
    "steps = 0\n",
    "movement_classes = []\n",
    "\n",
    "# Contadores para cada tipo de movimento\n",
    "# Counters for each type of movement\n",
    "movement_counts = {\"Movimento A\": 0, \"Movimento B\": 0, \"Movimento C\": 0, \"Movimento Desconhecido\": 0}\n",
    "\n",
    "# Verificar movimento significativo entre frames\n",
    "# Check for significant movement between frames\n",
    "def is_significant_movement(position1, position2, threshold=min_movement_threshold):\n",
    "    return np.linalg.norm(np.array(position1) - np.array(position2)) > threshold\n",
    "\n",
    "# Processar cada frame do vídeo\n",
    "# Process each frame of the video\n",
    "for frame_idx in range(frames_to_process):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Fazer predição com o modelo\n",
    "    # Make prediction with the model\n",
    "    results = model(frame)\n",
    "\n",
    "    # Renderizar resultados na imagem e coletar posições do ombro, quadril direito e pés\n",
    "    # Render results on the image and collect positions of the shoulder, right hip, and feet\n",
    "    for result in results:\n",
    "        if hasattr(result, 'keypoints') and result.keypoints is not None and len(result.boxes) > 0:\n",
    "            keypoints = result.keypoints.data[0].cpu().numpy()  # Assumindo que os keypoints estão no formato esperado / Assuming keypoints are in the expected format\n",
    "            confidence = result.boxes.conf[0].item()  # Acessar a confiança da detecção / Access detection confidence\n",
    "            if confidence >= min_confidence:\n",
    "                print(f\"Frame {frame_idx} Keypoints detectados:\")\n",
    "                for idx, (x, y, c) in enumerate(keypoints):\n",
    "                    print(f\"Keypoint {idx}: ({x}, {y}), Confiança: {c}\")\n",
    "                if len(keypoints) > max(right_shoulder_id, right_hip_id, right_foot_id, left_foot_id):\n",
    "                    right_shoulder = keypoints[right_shoulder_id]\n",
    "                    right_hip = keypoints[right_hip_id]\n",
    "                    right_foot = keypoints[right_foot_id]\n",
    "                    left_foot = keypoints[left_foot_id]\n",
    "\n",
    "                    if len(right_shoulder_positions) > 0:\n",
    "                        if is_significant_movement(right_shoulder_positions[-1], (right_shoulder[0], right_shoulder[1])):\n",
    "                            right_shoulder_positions.append((right_shoulder[0], right_shoulder[1]))\n",
    "                    \n",
    "                    if len(right_hip_positions) > 0:\n",
    "                        if is_significant_movement(right_hip_positions[-1], (right_hip[0], right_hip[1])):\n",
    "                            right_hip_positions.append((right_hip[0], right_hip[1]))\n",
    "                    \n",
    "                    if len(right_foot_positions) > 0:\n",
    "                        if is_significant_movement(right_foot_positions[-1], (right_foot[0], right_foot[1])):\n",
    "                            right_foot_positions.append((right_foot[0], right_foot[1]))\n",
    "                            steps += 1  # Contar apenas se houver movimento significativo / Count only if there is significant movement\n",
    "                    \n",
    "                    if len(left_foot_positions) > 0:\n",
    "                        if is_significant_movement(left_foot_positions[-1], (left_foot[0], left_foot[1])):\n",
    "                            left_foot_positions.append((left_foot[0], left_foot[1]))\n",
    "\n",
    "                    print(f\"Right Hip Position: {right_hip}\")\n",
    "\n",
    "                    # Detectar saltos baseados na posição vertical do quadril\n",
    "                    # Detect jumps based on the vertical position of the hip\n",
    "                    if right_hip[1] < height * 0.5:  # Ajustar este valor conforme necessário para detectar saltos / Adjust this value as needed to detect jumps\n",
    "                        if not in_air:\n",
    "                            in_air = True\n",
    "                            jumps += 1\n",
    "                            spins_per_jump.append(0)\n",
    "                            print(f\"Salto detectado no frame {frame_idx}\")\n",
    "                    else:\n",
    "                        if in_air:\n",
    "                            in_air = False\n",
    "                            spins = count_spins(right_shoulder_positions[-fps:])\n",
    "                            spins_per_jump[-1] = spins\n",
    "                            total_air_spins += spins\n",
    "                            movement_class = classify_movement(spins)\n",
    "                            movement_classes.append(movement_class)\n",
    "                            movement_counts[movement_class] += 1\n",
    "\n",
    "                    # Contar giros no solo\n",
    "                    # Count ground spins\n",
    "                    if not in_air:\n",
    "                        ground_spins = count_spins(right_shoulder_positions[-fps:])\n",
    "                        total_ground_spins += ground_spins\n",
    "\n",
    "    # Renderizar resultados na imagem\n",
    "    # Render results on the image\n",
    "    if len(results) > 0:\n",
    "        rendered_frame = results[0].plot()\n",
    "    else:\n",
    "        rendered_frame = frame\n",
    "    \n",
    "    # Adicionar contadores na tela\n",
    "    # Add counters on the screen\n",
    "    font_scale = 0.8\n",
    "    thickness = 2\n",
    "    cv2.putText(rendered_frame, f\"Saltos: {jumps}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    cv2.putText(rendered_frame, f\"Giros no Ar: {total_air_spins}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    cv2.putText(rendered_frame, f\"Giros no Solo: {total_ground_spins}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    cv2.putText(rendered_frame, f\"Passos: {steps}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # Adicionar contadores de movimentos na tela\n",
    "    # Add movement counters on the screen\n",
    "    y_offset = 150\n",
    "    for movement, count in movement_counts.items():\n",
    "        cv2.putText(rendered_frame, f\"{movement}: {count}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "        y_offset += 30\n",
    "\n",
    "    # Escrever o frame processado no vídeo de saída\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(rendered_frame)\n",
    "\n",
    "# Calcular a velocidade dos pés e detectar corrida ou caminhada\n",
    "# Calculate foot speed and detect running or walking\n",
    "right_foot_speeds = calculate_speed(right_foot_positions, fps)\n",
    "left_foot_speeds = calculate_speed(left_foot_positions, fps)\n",
    "\n",
    "running_right, walking_right = detect_running_walking(right_foot_speeds)\n",
    "running_left, walking_left = detect_running_walking(left_foot_speeds)\n",
    "\n",
    "total_running = running_right + running_left\n",
    "total_walking = walking_right + walking_left\n",
    "\n",
    "# Liberar os objetos de captura e escrita de vídeo\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Exibir os resultados finais\n",
    "# Display final results\n",
    "print(f\"Total de saltos detectados: {jumps}\")\n",
    "print(f\"Giros no ar detectados por salto: {spins_per_jump}\")\n",
    "print(f\"Giros no solo: {total_ground_spins}\")\n",
    "print(f\"Contagem de movimentos: {movement_counts}\")\n",
    "print(f\"Passos detectados: {steps}\")\n",
    "print(f\"Correndo: {total_running}, Andando: {total_walking}\")\n",
    "print(f\"Vídeo salvo em: {output_video_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
